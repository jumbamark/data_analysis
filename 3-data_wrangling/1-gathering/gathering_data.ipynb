{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gathering data is the first step in data wrangling\n",
    "- It varies from project to project. Sometimes you are given data or pointed to it. Sometimes you need to search for the right data for your project\n",
    "- Sometimes the data you need isn't readily available and you need to generate it yourself somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Finding the best movies?\n",
    "#### How to find the best movies\n",
    "- You may check movie rating websites like Rotten tomatoes or IMDB to help you choose. These sites contain a number of different metrics which are used to evaluate whether or not you will like a movie.\n",
    "- However because the metrics don't show on the same page,figuring out the best movie can get confusing\n",
    "\n",
    "### Use a scatter plot\n",
    "- We can start with [Rotten Tomatoes: Top 100 Movies of All Time](https://www.rottentomatoes.com/browse/movies_at_home/critics:certified_fresh?page=1)\n",
    "- We can use a scatter plot to look at auddience scores vs critic scores for each movie\n",
    "\n",
    "- If we put audience scores on the horizontal axis and critic scores on the vertical axis, movies in the top right quadrant are amazing movies with high audience and critic scores\n",
    "- Movies in the bottom right quadrant are critically underrated with high audience scores and low critic scores\n",
    "\n",
    "### Generate a Word Cloud\n",
    "- For lot's of people, Rodger Ebert's movie review was the only review they needed because he explained the movie in such away that they would know whether they would like it or not\n",
    "- Wouldn't it be neat if we had a word cloud for each of the movies in the top 100 list at [RodgerEbert.com](https://www.rogerebert.com/)?\n",
    "- We can use a Andreas Mueller's [Word Cloud Generator in Python](https://amueller.github.io/word_cloud/) to help.\n",
    "\n",
    "- To create both of these visualizations, the data is in different spots and it will require some craftiness to gather it all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Pre-Gathered Dataset\n",
    "- The dataset has four columns; Rank, Title, Rating, Number of Reviews\n",
    "- The file is in **TSV**, tab separated values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat File Structure\n",
    "- Flat files contain tabular data in plain text format with one data recorded per line and each record or line having one or more fields\n",
    "- Thee fields are separated with delimiters like commas, tabs or colons\n",
    "\n",
    "#### Advantages of flat files\n",
    "- They are text files and therefore human readable\n",
    "- Lightweight\n",
    "- Simple to understand\n",
    "- Great for small dataset\n",
    "\n",
    "#### Disadvantages\n",
    "- Lack of standards\n",
    "- Data redundancy\n",
    "- Sharing data can be cumbersome\n",
    "- Not great for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Files in Python\n",
    "- Because flat files are human readable you can easily write your own code to parse or understand these files using python\n",
    "- Open the file, read the text by line, Separate each lines content by the delimeter, store everything in your data structure of choice\n",
    "\n",
    "\n",
    "###### Reading comma separated data\n",
    "- We use `read_csv` function to bring csv data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the Rotten Tomatoes bestofrt TSV file into a data frame\n",
    "df = pd.read_csv(\"bestofrt.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>title</th>\n",
       "      <th>number_of_critic_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>The Wizard of Oz (1939)</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>Get Out (2017)</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>Mad Max: Fury Road (2015)</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  critic_score                      title  number_of_critic_ratings\n",
       "0        1            99    The Wizard of Oz (1939)                       110\n",
       "1        2           100        Citizen Kane (1941)                        75\n",
       "2        3           100       The Third Man (1949)                        77\n",
       "3        4            99             Get Out (2017)                       282\n",
       "4        5            97  Mad Max: Fury Road (2015)                       370"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if the file was imported correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source: Web Scrapping\n",
    "### Data isn't always easy to access\n",
    "- We want to get Rotten Tomatoes audience scores and the number of audience reviews to add to our dataset\n",
    "- Since its not easily accessible from the website, we need to do **web scrapping** which allows us to extract data from website using code\n",
    "\n",
    "### How does web scrapping work\n",
    "- Website data is written in **HTML** which uses tags to structure the page. Because HTML and its tags are just text, the text can be accesses using parsers\n",
    "- We'll be using a python parser called **[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)**\n",
    "- Start by exploring the structure of HTML files\n",
    "\n",
    "### Saving HTML\n",
    "#### Accessing the HTML\n",
    "- __Manual Access__\n",
    "- The quick way to get HTML data is by saving the HTML file to your computer manually. You can do it by clicking **Save** on your browser.\n",
    "\n",
    "* __Programmatic Access__\n",
    "- Programmatic access is preffrered for scalability and reproducibility. Two options include;\n",
    "1. Downloading HTML file programmatically\n",
    "\n",
    "    ```python\n",
    "    import requests\n",
    "    url = 'https://www.rottentomatoes.com/m/et_the_extraterrestrial'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # saving HTML to file\n",
    "    with open('et_the_extraterrestrial.html', 'w') as file:\n",
    "        file.write(response.content)\n",
    "    # This is code to download 1 file, to download all 100 files we'll have to put it in a loop\n",
    "    ```\n",
    "2. Working with the response content live in your computers memory using the  BeautifulSoup HTML parser (doesn't require saving a file to your computer at all)\n",
    "\n",
    "    ```python\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing HTML in this lesson\n",
    "- Open the pre gathered htm folder (rt_html) which contains the rotten tomatoes HTMl for each of the Top 100 Movies Of All Time\n",
    "- We are using pre gathered data in this code because scrapping code can break easily when web redesigns occur, which makes scrapping brittle and not recommended for projects with longevity\n",
    "- There are some [ethical issues](https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01) involved in web scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Files in Python\n",
    "- HTML files are text files that can be opened and inspected in the text editor which means you can write your own code to pass the text\n",
    "- For example to get our audience score metrics, we could find all the instances of the `span` tag using Python tools like `str.find` or regular expressions to search for and extract patterns in the text. But we have a better tool\n",
    "\n",
    "### Beautiful Soup\n",
    "- **Beautiful soup** is an HTML parser written in the python programming language\n",
    "- The name is derived from the \"tag soup\" which refers to the unstructured and difficult-to-parse HTML found on many websites\n",
    "\n",
    "## Using Beautiful Soup\n",
    "- To get started we need to import Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next we make the soup by passing the path to the HTML file into a filehandle then passing that filehandle into the BeautifulSoup constructor along with the parser\n",
    "- We are using `lxml` which is the most popular parser\n",
    "- `conda install lxml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rt_html/12_years_a_slave.html\") as file:\n",
    "    soup = BeautifulSoup(file, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This results looks exactly like an HTML document and we can use methods in the Beautiful Soup library to easily find and extract data from this HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Find Method\n",
    "- `find()` is one of the most popular Beautiful Soup methods. It's similar to the find feature in a text editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>12 Years a Slave (2013) - Rotten Tomatoes</title>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the title of our movie\n",
    "soup.find('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we get the title element of the web page and not the title of the movie\n",
    "- To get the movie title we need to do some string slicing\n",
    "- We can use `.contents` to return a list of the tag's children. Because there is only one item in the title tag, the list is one item long so we can access it using the index `[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12 Years a Slave\\xa0(2013) - Rotten Tomatoes']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .contents returns a list of all the tags children\n",
    "soup.find('title').contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12 Years a Slave\\xa0(2013)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12 Years a Slave\\xa0(2013)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# soup.find('title').count[0][:-len(' - Rotten Tomatoes')]\n",
    "soup.find('title').string[:-len(' - Rotten Tomatoes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(' - Rotten Tomatoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `\\xa0` in the returned title is unicode from non-breaking space which we would need to deal with later in the cleaning step\n",
    "\n",
    "- **Resources**\n",
    "- Beautiful Soup`.find` [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find)\n",
    "- Beautiful Soup`.contents` [documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#contents-and-children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are going to use Beautiful Soup to extract our desired Audience Score Metric and number of audience ratings along with the movie title for each html file then save them in a pandas DataFrame\n",
    "- Write code that;\n",
    "    * creates an empty list `df_list` to which dictionaries will be appended. The list of dictionaries will eventually be converted into a pandas DataFrame\n",
    "    * Loops through each movie's Rotten Tomatoes HTML file in the `rt_html` folder\n",
    "    * Opens each HTML file and passes it into a file handle called file\n",
    "    * creates a DataFrame called df by converting `df_list` using the `pd.DataFrame` constructor\n",
    "- [Resource](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make the soup by passing in the file handle\n",
    "- The first thing to grab from the HTML was the title, use the find method to get the only title tag in the document and accessing contents of that file using `.contents` and grabbing the first item in that tag and slicing off the last `-Rotten Tomatoes`\n",
    "\n",
    "- The next thing to grab was the audience score, take a look at our html code to see where that's at (there's a 72% and its within a div with the class titled; `audience-score meter`).The 72% is within the only span tag within the outermost div tag. Because its the first span tag we can use the `.find` method\n",
    "\n",
    "- To grab the number of audience rating s is abit complicated. If we scroll down we see the user ratings. The outer most div has the class `audience-info hidden-xs superPageFontColor`\n",
    "- When you print it out you notice within that div tag is two other div tags and the number of audience ratings is in the second div tag. We can use `findall` and take the second item in that returned list. The second item being index number 1, if we look at the contents we see the number of audience ratings, third item index number 2\n",
    "- There is a bunch of white space we'll strip out using the python strip function. It's currently in string form, we later have to convert to integer. To do that we'll have to remove the commas. We'll do that using the python's replace character (replacing commas with empty characters)\n",
    "\n",
    "- All that's left to do is convert our list of dictionaries, `df_list` to a pandas DataFrame\n",
    "- Make sure the pandas df is imported and aliased then specify the column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries to build file by file and later convert to a DataFrame\n",
    "df_list= []\n",
    "folder = 'rt_html'\n",
    "for movie_html in os.listdir(folder):\n",
    "    with open(os.path.join(folder, movie_html)) as file:\n",
    "        soup = BeautifulSoup(file, 'lxml')\n",
    "        title = soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
    "        audience_score = soup.find('div', class_='audience-score meter').find('span').contents[0][:-1]\n",
    "        num_audience_ratings = soup.find('div', class_='audience-info hidden-xs superPageFontColor')\n",
    "        # print(num_audience_ratings)\n",
    "        # break\n",
    "        num_audience_ratings = num_audience_ratings.find_all('div')[1].contents\n",
    "        # print(num_audience_ratings)\n",
    "        # break\n",
    "        num_audience_ratings = num_audience_ratings[2].strip().replace(',', '')\n",
    "        # print(num_audience_ratings)\n",
    "        # break\n",
    "\n",
    "        # appending to list of dictionaries\n",
    "        df_list.append(\n",
    "            {\n",
    "                'title': title,\n",
    "                'audience_score': int(audience_score),\n",
    "                'number_of_audience_ratings': int(num_audience_ratings)\n",
    "            }\n",
    "        )\n",
    "\n",
    "df = pd.DataFrame(df_list, columns=['title', 'audience_score', 'number_of_audience_ratings'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>audience_score</th>\n",
       "      <th>number_of_audience_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Big Sick (2017)</td>\n",
       "      <td>90</td>\n",
       "      <td>23391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Quiet on the Western Front (1930)</td>\n",
       "      <td>89</td>\n",
       "      <td>17768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gone With the Wind (1939)</td>\n",
       "      <td>93</td>\n",
       "      <td>292794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zootopia (2016)</td>\n",
       "      <td>92</td>\n",
       "      <td>98633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bicycle Thieves (Ladri di biciclette) (1949)</td>\n",
       "      <td>94</td>\n",
       "      <td>33723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "      <td>94</td>\n",
       "      <td>149772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Pinocchio (1940)</td>\n",
       "      <td>72</td>\n",
       "      <td>278682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Argo (2012)</td>\n",
       "      <td>90</td>\n",
       "      <td>207373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Grapes of Wrath (1940)</td>\n",
       "      <td>88</td>\n",
       "      <td>23954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Godfather, Part II (1974)</td>\n",
       "      <td>97</td>\n",
       "      <td>409574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  audience_score  \\\n",
       "0                            The Big Sick (2017)              90   \n",
       "1          All Quiet on the Western Front (1930)              89   \n",
       "2                      Gone With the Wind (1939)              93   \n",
       "3                                Zootopia (2016)              92   \n",
       "4   Bicycle Thieves (Ladri di biciclette) (1949)              94   \n",
       "..                                           ...             ...   \n",
       "95                      L.A. Confidential (1997)              94   \n",
       "96                              Pinocchio (1940)              72   \n",
       "97                                   Argo (2012)              90   \n",
       "98                    The Grapes of Wrath (1940)              88   \n",
       "99                 The Godfather, Part II (1974)              97   \n",
       "\n",
       "    number_of_audience_ratings  \n",
       "0                        23391  \n",
       "1                        17768  \n",
       "2                       292794  \n",
       "3                        98633  \n",
       "4                        33723  \n",
       "..                         ...  \n",
       "95                      149772  \n",
       "96                      278682  \n",
       "97                      207373  \n",
       "98                       23954  \n",
       "99                      409574  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at the data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the cell below to see if your solution is correct. If an AssertError is thrown your solution is incorrect. If no error is thrown your solution is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution test\n",
    "df_solution = pd.read_pickle('df_solution.pkl')\n",
    "df.sort_values('title', inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df_solution.sort_values('title', inplace=True)\n",
    "df_solution.reset_index(inplace=True, drop=True)\n",
    "pd.testing.assert_frame_equal(df, df_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Information\n",
    "- [Learning about the non breaking issue encounterd earlier](https://stackoverflow.com/questions/19508442/beautiful-soup-and-unicode-problems)\n",
    "- [Fixing the non-breaking space issue](https://stackoverflow.com/questions/10993612/how-to-remove-xa0-from-string-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We've gathered enough data to produce a scatter plot with audience on the horizontal axis and critical score on the vertical axis\n",
    "- The next step includes joining our two dataFrames then visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Files from the internet\n",
    "#### Starting the Roger Ebert review word cloud\n",
    "- We'll need the text from each of his reviews for each of the Rotten tomatoes Top 100 movies of all time list that lives on his website\n",
    "- This text has been pre gathered in the form of 100.txtx files that can be downloaded pragmatically\n",
    "- Downoading files from the internet pragmatically is best for scalability and reproducibility\n",
    "- Only python's request library is needed in practice but a bit of HTTP (hyper text transfer protocal) helps in understanding what's going on under the hood\n",
    "\n",
    "### HTTP\n",
    "- Is the language that web browsers (chrome, safari) and web servers (apache, basically computers where the contents of a website are stored) use to communicate with each other\n",
    "- Every time you open a webpage or download a file or watch a video its HTTP that makes it possible\n",
    "- HTTP is a request/response protocol\n",
    "    * The computer (client) sends a request to a server for some file, the web server sends back a response if the request is valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request: HTTP for Humans\n",
    "- Python's request library makes http requests easy, it has a method called `GET` which will send the request for us, return the contents of the file we requested(text file) which we can then save to a file\n",
    "- Programmatically downloading a file from the internet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the folder ebert_reviews if it doesn't exists already\n",
    "folder_name = \"/home/mark/data_science/Udacity/data_analysis/3-data_wrangling/1-gathering/ebert_reviews\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# request code\n",
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_11-e.t.-the-extra-terrestrial/11-e.t.-the-extra-terrestrial.txt\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the request is succesful the HTTP request will return a 200 response, the status code for a succesful response\n",
    "- This tells you that all the text in our text file is in the computers working memory in the body of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'E.T. The Extra-Terrestrial (1982)\\nhttp://www.rogerebert.com/reviews/great-movie-et-the-extra-terrestrial-1982\\nDear Raven and Emil:\\n\\nSunday we sat on the big green couch and watched \"E.T. The Extra-Terrestrial\" together with your mommy and daddy. It was the first time either of you had seen it, although you knew a little of what to expect because we took the \"E.T.\" ride together at the Universal tour. I had seen the movie lots of times since it came out in 1982, so I kept one eye on the screen and the other on the two of you. I wanted to see how a boy on his fourth birthday, and a girl who had just turned 7 a week ago, would respond to the movie.\\n\\nWell, it \"worked\" for both of you, as we say in Grandpa Roger\\'s business.\\n\\nRaven, you never took your eyes off the screen--not even when it looked like E.T. was dying and you had to scoot over next to me because you were afraid.\\n\\nEmil, you had to go sit on your dad\\'s knee a couple of times, but you never stopped watching, either. No trips to the bathroom or looking for lost toys: You were watching that movie with all of your attention.\\n\\nThe early scenes show a spaceship landing, and they suggest that a little creature has been left behind. The ship escapes quickly after men in pickup trucks come looking for it. Their headlights and flashlights make visible beams through the foggy night, and you remembered the same effect during the ride at Universal. And the keys hanging from their belts jangle on the soundtrack. It\\'s how a lost little extraterrestrial would experience it.\\n\\nThen there are shots of a suburban house, sort of like the one you live in, with a wide driveway and a big backyard. A little boy named Elliott (Henry Thomas) is in the yard when he thinks he sees or hears something. We already know that it\\'s E.T.\\n\\nThe camera watches Elliott moving around. And Raven, that\\'s when you asked me, \"Is this E.T.\\'s vision?\" And I said, yes, we were seeing everything now from E.T.\\'s point of view. And I thought you\\'d asked a very good question, because most kids your age wouldn\\'t have noticed that the camera had a point of view--that we were seeing everything from low to the ground, as a short little creature would view it, and experiencing what he (or she) would see after wandering out of the woods on a strange planet.\\n\\nWhile we were watching, I realized how right you were to ask that question. The whole movie is based on what moviemakers call \"point of view.\" Almost every single important shot is seen either as E.T. would see it, or as Elliott would see it. And things are understood as they would understand them. There aren\\'t any crucial moments where the camera pulls back and seems to be a grownup. We\\'re usually looking at things through a child\\'s eye--or an alien\\'s.\\n\\nWhen Elliott and E.T. see each other for the first time, they both jump back in fright and surprise, and let out yelps. We see each of them from the other\\'s point of view. When the camera stands back to show a whole scene, it avoids showing it through adult eyes. There\\'s a moment, for example, when Elliott\\'s mom (Dee Wallace Stone) is moving around doing some housework, and never realizes that E.T. is scurrying around the room just out of her line of sight. The camera stays back away from her. We don\\'t see her looking this way and that, because it\\'s not about which way she\\'s looking.\\n\\nLater, we do get one great shot that shows what she sees: She\\'s looking in Elliott\\'s closet at all of his stuffed toys lined up, and doesn\\'t realize one of the \"toys\" is actually E.T. We all laughed at that shot, but it was an exception; basically we looked out through little eyes, not big ones. (For example, in the scene where they take E.T. trick-or-treating with a sheet over his head, and we can see out like he can through the holes in the sheet.)\\n\\nLater, in the scenes that really worried you, Raven, the men in the trucks come back. They know E.T. is in Elliott\\'s house, and they\\'re scientists who want to examine the alien creature. But there isn\\'t a single moment when they use grownup talk and explain what they\\'re doing. We only hear small pieces of their dialogue, as Elliott might overhear it.\\n\\nBy then we know Elliott and E.T. are linked mentally, so Elliott can sense that E.T. is dying. Elliott cries out to the adults to leave E.T. alone, but the adults don\\'t take him seriously. A kid knows what that feels like. And then, when Elliott gets his big brother to drive the getaway car, and the brother says, \"I\\'ve never driven in forward before!\\'\\' you could identify with that. Kids are always watching their parents drive, and never getting to do it themselves.\\n\\nWe loved the scene where the bicycles fly. We suspected it was coming, because E.T. had taken Elliott on a private bike flight earlier, so we knew he could do it. I was thinking that the chase scene before the bikes fly was a little too long, as if Steven Spielberg (who made the film) was trying to build up too much unnecessary suspense. But when those bikes took off, what a terrific moment! I remember when I saw the movie at Cannes; even the audience there, people who had seen thousands of movies, let out a whoop at that moment.\\n\\nThen there\\'s the scene at the end. E.T. has phoned home, and the spaceship has come to get him. He\\'s in the woods with Elliott. The gangplank on the ship comes down, and in the doorway we can see another creature like E.T. standing with the light behind.\\n\\nEmil, you said, \"That\\'s E.T.\\'s mommy!\\'\\' And then you paused a second, and said, \"Now how did I know that?\\'\\'\\n\\nWe all laughed, because you made it sound funny, as you often do--you\\'re a natural comedian. But remembering it now, I asked myself--how did Emil know that? It could have been E.T.\\'s daddy, or sister, or the pilot of the ship. But I agree with you it probably was his mommy, because she sounded just like a mommy as she made the noise of calling E.T.\\n\\nAnd then I thought, the fact that you knew that was a sign of how well Steven Spielberg made his movie. At 4, you are a little young to understand \"point of view,\\'\\' but you are old enough to react to one. For the whole movie, you\\'d been seeing almost everything through the eyes of E.T. or Elliott. By the last moments, you were identifying with E.T. And who did he miss the most? Who did he want to see standing in the spaceship door for him? His mommy.\\n\\nOf course, maybe Steven Spielberg didn\\'t see it the same way, and thought E.T. only seemed like a kid and was really 500 years old. That doesn\\'t matter, because Spielberg left it open for all of us. That\\'s the sign of a great filmmaker: He only explains what he has to explain, and with a great movie the longer it runs, the less has to be explained. Some other filmmaker who wasn\\'t so good might have had subtitles saying, \"E.T.? Are you out there? It\\'s Mommy!\\'\\' But that would have been dumb.\\n\\nAnd it would have deprived you, Emil, of the joy of knowing it was E.T.\\'s mommy, and the delight of being able to tell the rest of us.\\n\\nWell, that\\'s it for this letter. We had a great weekend, kids. I was proud of how brave you both were during your first pony rides. And proud of what good movie critics you are, too.\\n\\nLove, Grandpa Roger'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the content and write to a file\n",
    "- use the `requests.content` method and some basic I/O to save this file to our computer\n",
    "- So we'll open a file called `11-e.t-the-extra-terrestrial.txt` i.e everything after the last slash in the URl \n",
    "- To get everything after the last slash we'll use python's split function and select the last item in the list returned\n",
    "- We need to open this file which will then write the contents of the response variable to \n",
    "- We'll open this in the `wb` mode which stands for write binary because the `response.content` is in bytes,not text\n",
    "- When we open the files in a text editor or pandas the bytes will be rendered as human readable text\n",
    "- Then we write to the file handle we've opened, `file.write.response.content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading one file programmatically\n",
    "with open(os.path.join(folder_name, url.split('/')[-1]), mode = 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11-e.t.-the-extra-terrestrial.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the contents of our folder to make sure it worked\n",
    "os.listdir(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we have lots of files to download though like we do for all of these Ebert reviews for the top 100 Rotten Tomatoes movie list, we can use a for loop over all of the file URLs to minimize code repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebert_review_urls = [\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9900_1-the-wizard-of-oz-1939-film/1-the-wizard-of-oz-1939-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9901_2-citizen-kane/2-citizen-kane.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9901_3-the-third-man/3-the-third-man.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_4-get-out-film/4-get-out-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_5-mad-max-fury-road/5-mad-max-fury-road.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_6-the-cabinet-of-dr.-caligari/6-the-cabinet-of-dr.-caligari.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_7-all-about-eve/7-all-about-eve.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_8-inside-out-2015-film/8-inside-out-2015-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_9-the-godfather/9-the-godfather.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_10-metropolis-1927-film/10-metropolis-1927-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_11-e.t.-the-extra-terrestrial/11-e.t.-the-extra-terrestrial.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_12-modern-times-film/12-modern-times-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_14-singin-in-the-rain/14-singin-in-the-rain.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_15-boyhood-film/15-boyhood-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_16-casablanca-film/16-casablanca-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_17-moonlight-2016-film/17-moonlight-2016-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_18-psycho-1960-film/18-psycho-1960-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_19-laura-1944-film/19-laura-1944-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_20-nosferatu/20-nosferatu.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_21-snow-white-and-the-seven-dwarfs-1937-film/21-snow-white-and-the-seven-dwarfs-1937-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_22-a-hard-day27s-night-film/22-a-hard-day27s-night-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_23-la-grande-illusion/23-la-grande-illusion.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_25-the-battle-of-algiers/25-the-battle-of-algiers.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_26-dunkirk-2017-film/26-dunkirk-2017-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_27-the-maltese-falcon-1941-film/27-the-maltese-falcon-1941-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_29-12-years-a-slave-film/29-12-years-a-slave-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_30-gravity-2013-film/30-gravity-2013-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_31-sunset-boulevard-film/31-sunset-boulevard-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_32-king-kong-1933-film/32-king-kong-1933-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_33-spotlight-film/33-spotlight-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_34-the-adventures-of-robin-hood/34-the-adventures-of-robin-hood.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_35-rashomon/35-rashomon.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_36-rear-window/36-rear-window.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_37-selma-film/37-selma-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_38-taxi-driver/38-taxi-driver.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_39-toy-story-3/39-toy-story-3.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_40-argo-2012-film/40-argo-2012-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_41-toy-story-2/41-toy-story-2.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_42-the-big-sick/42-the-big-sick.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_43-bride-of-frankenstein/43-bride-of-frankenstein.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_44-zootopia/44-zootopia.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_45-m-1931-film/45-m-1931-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_46-wonder-woman-2017-film/46-wonder-woman-2017-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_48-alien-film/48-alien-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_49-bicycle-thieves/49-bicycle-thieves.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_50-seven-samurai/50-seven-samurai.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_51-the-treasure-of-the-sierra-madre-film/51-the-treasure-of-the-sierra-madre-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_52-up-2009-film/52-up-2009-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_53-12-angry-men-1957-film/53-12-angry-men-1957-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_54-the-400-blows/54-the-400-blows.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9911_55-logan-film/55-logan-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9911_57-army-of-shadows/57-army-of-shadows.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9912_58-arrival-film/58-arrival-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9912_59-baby-driver/59-baby-driver.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_60-a-streetcar-named-desire-1951-film/60-a-streetcar-named-desire-1951-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_61-the-night-of-the-hunter-film/61-the-night-of-the-hunter-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_62-star-wars-the-force-awakens/62-star-wars-the-force-awakens.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_63-manchester-by-the-sea-film/63-manchester-by-the-sea-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_64-dr.-strangelove/64-dr.-strangelove.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_66-vertigo-film/66-vertigo-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_67-the-dark-knight-film/67-the-dark-knight-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_68-touch-of-evil/68-touch-of-evil.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_69-the-babadook/69-the-babadook.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_72-rosemary27s-baby-film/72-rosemary27s-baby-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9916_73-finding-nemo/73-finding-nemo.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9916_74-brooklyn-film/74-brooklyn-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9917_75-the-wrestler-2008-film/75-the-wrestler-2008-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9917_77-l.a.-confidential-film/77-l.a.-confidential-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_78-gone-with-the-wind-film/78-gone-with-the-wind-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_79-the-good-the-bad-and-the-ugly/79-the-good-the-bad-and-the-ugly.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_80-skyfall/80-skyfall.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_82-tokyo-story/82-tokyo-story.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_83-hell-or-high-water-film/83-hell-or-high-water-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_84-pinocchio-1940-film/84-pinocchio-1940-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_85-the-jungle-book-2016-film/85-the-jungle-book-2016-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991a_86-la-la-land-film/86-la-la-land-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991b_87-star-trek-film/87-star-trek-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991b_89-apocalypse-now/89-apocalypse-now.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_90-on-the-waterfront/90-on-the-waterfront.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_91-the-wages-of-fear/91-the-wages-of-fear.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_92-the-last-picture-show/92-the-last-picture-show.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_93-harry-potter-and-the-deathly-hallows-part-2/93-harry-potter-and-the-deathly-hallows-part-2.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_94-the-grapes-of-wrath-film/94-the-grapes-of-wrath-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_96-man-on-wire/96-man-on-wire.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_97-jaws-film/97-jaws-film.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_98-toy-story/98-toy-story.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_99-the-godfather-part-ii/99-the-godfather-part-ii.txt',\n",
    "    'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_100-battleship-potemkin/100-battleship-potemkin.txt'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Writing a loop to download all of the Rodger Ebert review files programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"/home/mark/data_science/Udacity/data_analysis/3-data_wrangling/1-gathering/ebert_reviews\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "\n",
    "for url in ebert_review_urls:\n",
    "    response = requests.get(url)\n",
    "    with open(os.path.join(folder_name, url.split('/')[-1]), mode = 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text File Structure\n",
    "- A text file refers to a file that uses a specific character set and contains no formatting like italics or bolding and also has no media like images or video\n",
    "- Lines of text are separated by new line characters or backslash end in python. These characters are invisible in most software applications like text editors\n",
    "- Flat files like `tsv` are technically text files but they have a specific structure\n",
    "- These Rodger Ebert review text files though are just blobs of text, no defined structure like in the tabular structure. All of the techniques we are going to apply though can be done on any text file regardless of structure\n",
    "- Regarding the specific character sets, have you ever opened a document and its characters are all garbled like a bunch of question marks in a row or a bunch of weird characters? that's because your text editor, browser or word processor or whatever else you are trying to read the document is assuming the wrong encoding or the wrong scheme for converting the character set bits to letters and numbers.\n",
    "- You need to select the right encoding to display the document properly\n",
    "- Character sets and encodings are two things that every programmer needs to be aware of when working with any text data including flat files like csv files, html and json\n",
    "\n",
    "- **Character sets** are the collections of characters that are available for use in a system\n",
    "- **Encoding** is the scheme for converting the character sets bits to letters and numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Files in Python\n",
    "- Gathering data from text files in python mean opening and reading from files\n",
    "- If you are using pandas it also means storing the text data you just read in a pandas dataframe\n",
    "- We have 88 Roger Ebert reviews to open and read. We'll need a loop to iterate through all the files in this folder to open and read each\n",
    "- There are two ways to do it;\n",
    "    * Using the `os` library\n",
    "    * using the `glob` library\n",
    "- The glob library allows for Unix-style pathname pattern expansion(using glob patterns to specify sets of filenames)\n",
    "- These glob patterns use wildcard characters\n",
    "- `glob.glob(pathname, *, recursive=False)` returns a list of pathnames that match pathname\n",
    "- We want all file names that end in `.txt` which in our folder is all of them and because glob.glob returns a list we can loop through that directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebert_reviews/66-vertigo-film.txt\n",
      "ebert_reviews/31-sunset-boulevard-film.txt\n",
      "ebert_reviews/32-king-kong-1933-film.txt\n",
      "ebert_reviews/77-l.a.-confidential-film.txt\n",
      "ebert_reviews/55-logan-film.txt\n",
      "ebert_reviews/37-selma-film.txt\n",
      "ebert_reviews/9-the-godfather.txt\n",
      "ebert_reviews/7-all-about-eve.txt\n",
      "ebert_reviews/29-12-years-a-slave-film.txt\n",
      "ebert_reviews/16-casablanca-film.txt\n",
      "ebert_reviews/54-the-400-blows.txt\n",
      "ebert_reviews/94-the-grapes-of-wrath-film.txt\n",
      "ebert_reviews/53-12-angry-men-1957-film.txt\n",
      "ebert_reviews/35-rashomon.txt\n",
      "ebert_reviews/91-the-wages-of-fear.txt\n",
      "ebert_reviews/73-finding-nemo.txt\n",
      "ebert_reviews/93-harry-potter-and-the-deathly-hallows-part-2.txt\n",
      "ebert_reviews/40-argo-2012-film.txt\n",
      "ebert_reviews/38-taxi-driver.txt\n",
      "ebert_reviews/43-bride-of-frankenstein.txt\n",
      "ebert_reviews/45-m-1931-film.txt\n",
      "ebert_reviews/75-the-wrestler-2008-film.txt\n",
      "ebert_reviews/18-psycho-1960-film.txt\n",
      "ebert_reviews/15-boyhood-film.txt\n",
      "ebert_reviews/11-e.t.-the-extra-terrestrial.txt\n",
      "ebert_reviews/98-toy-story.txt\n",
      "ebert_reviews/87-star-trek-film.txt\n",
      "ebert_reviews/44-zootopia.txt\n",
      "ebert_reviews/10-metropolis-1927-film.txt\n",
      "ebert_reviews/58-arrival-film.txt\n",
      "ebert_reviews/26-dunkirk-2017-film.txt\n",
      "ebert_reviews/72-rosemary27s-baby-film.txt\n",
      "ebert_reviews/19-laura-1944-film.txt\n",
      "ebert_reviews/34-the-adventures-of-robin-hood.txt\n",
      "ebert_reviews/82-tokyo-story.txt\n",
      "ebert_reviews/33-spotlight-film.txt\n",
      "ebert_reviews/39-toy-story-3.txt\n",
      "ebert_reviews/51-the-treasure-of-the-sierra-madre-film.txt\n",
      "ebert_reviews/64-dr.-strangelove.txt\n",
      "ebert_reviews/8-inside-out-2015-film.txt\n",
      "ebert_reviews/48-alien-film.txt\n",
      "ebert_reviews/60-a-streetcar-named-desire-1951-film.txt\n",
      "ebert_reviews/30-gravity-2013-film.txt\n",
      "ebert_reviews/67-the-dark-knight-film.txt\n",
      "ebert_reviews/25-the-battle-of-algiers.txt\n",
      "ebert_reviews/17-moonlight-2016-film.txt\n",
      "ebert_reviews/6-the-cabinet-of-dr.-caligari.txt\n",
      "ebert_reviews/57-army-of-shadows.txt\n",
      "ebert_reviews/20-nosferatu.txt\n",
      "ebert_reviews/27-the-maltese-falcon-1941-film.txt\n",
      "ebert_reviews/85-the-jungle-book-2016-film.txt\n",
      "ebert_reviews/50-seven-samurai.txt\n",
      "ebert_reviews/41-toy-story-2.txt\n",
      "ebert_reviews/14-singin-in-the-rain.txt\n",
      "ebert_reviews/62-star-wars-the-force-awakens.txt\n",
      "ebert_reviews/61-the-night-of-the-hunter-film.txt\n",
      "ebert_reviews/99-the-godfather-part-ii.txt\n",
      "ebert_reviews/52-up-2009-film.txt\n",
      "ebert_reviews/4-get-out-film.txt\n",
      "ebert_reviews/46-wonder-woman-2017-film.txt\n",
      "ebert_reviews/84-pinocchio-1940-film.txt\n",
      "ebert_reviews/68-touch-of-evil.txt\n",
      "ebert_reviews/78-gone-with-the-wind-film.txt\n",
      "ebert_reviews/22-a-hard-day27s-night-film.txt\n",
      "ebert_reviews/2-citizen-kane.txt\n",
      "ebert_reviews/42-the-big-sick.txt\n",
      "ebert_reviews/80-skyfall.txt\n",
      "ebert_reviews/63-manchester-by-the-sea-film.txt\n",
      "ebert_reviews/21-snow-white-and-the-seven-dwarfs-1937-film.txt\n",
      "ebert_reviews/83-hell-or-high-water-film.txt\n",
      "ebert_reviews/12-modern-times-film.txt\n",
      "ebert_reviews/5-mad-max-fury-road.txt\n",
      "ebert_reviews/90-on-the-waterfront.txt\n",
      "ebert_reviews/89-apocalypse-now.txt\n",
      "ebert_reviews/69-the-babadook.txt\n",
      "ebert_reviews/59-baby-driver.txt\n",
      "ebert_reviews/36-rear-window.txt\n",
      "ebert_reviews/23-la-grande-illusion.txt\n",
      "ebert_reviews/3-the-third-man.txt\n",
      "ebert_reviews/97-jaws-film.txt\n",
      "ebert_reviews/92-the-last-picture-show.txt\n",
      "ebert_reviews/79-the-good-the-bad-and-the-ugly.txt\n",
      "ebert_reviews/74-brooklyn-film.txt\n",
      "ebert_reviews/1-the-wizard-of-oz-1939-film.txt\n",
      "ebert_reviews/96-man-on-wire.txt\n",
      "ebert_reviews/86-la-la-land-film.txt\n",
      "ebert_reviews/49-bicycle-thieves.txt\n",
      "ebert_reviews/100-battleship-potemkin.txt\n"
     ]
    }
   ],
   "source": [
    "for ebert_review in glob.glob(\"ebert_reviews/*.txt\"):\n",
    "    print(ebert_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can pass the entire path for each file into the open function in python, while we've been opening files with open then the path to the file then as file or whatever handle you use. In python3 when opening text to read you should use `open` with an explicit encoding which comes after the encoding parameter\n",
    "- Doing so means you get correctly decoded Unicode or an error right off the bat making it much easier to debug\n",
    "- The actual encoding depends on the source of the text (look at the html source file)\n",
    "- We don't want all the text data in one big chunk which will be done using `file.read`. We can check for one of the files with a print statement and then a break from the loop (prints the first file)\n",
    "- Instead we want the first line(movie title), second line (URL) and everything from the third line onwards (review text) as separate pieces of data so we cant just use `file.read`. Since text files are separated by new line characters and the file open returned from `with open as file` is an iterator we can read the file line by line\n",
    "- If you want to read one line you use `file.readline` which is the title of the movie\n",
    "- After printing there's abit of whitespace below which is actually the newline character, we can get rid of it by slicing it off at the end of the string\n",
    "- Next we grab the url and the full review text, before that recall that we need all this data in a pandas dataframe so we need to buil done\n",
    "- The most computationally efficeint way to do that is first to create an empty list then populate that list one by one as we iterate through the loop\n",
    "- We'll fill the list with dictionaries and later be converted to a pandas dataframe\n",
    "- Since review url is on line two we'll just use readline again to read the next line in the file. To read the next of the lines in the text file we use `file.read`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for ebert_review in glob.glob(\"ebert_reviews/*.txt\"):\n",
    "    with open(ebert_review, encoding='utf-8') as file:\n",
    "        # file.read()\n",
    "        # print(file.read())  # first file in the folder\n",
    "        # print(file.readline()[:-1]) # first line in the file, title of the movie\n",
    "        # break\n",
    "        title = file.readline()[:-1]\n",
    "        review_url = file.readline()[:-1]\n",
    "        review_text = file.read()\n",
    "        df_list.append({\n",
    "            'title': title,\n",
    "            'review_url': review_url,\n",
    "            'review_text': review_text\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(df_list, columns=['title', 'review_url', 'review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review_url</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vertigo (1958)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/great-movie-...</td>\n",
       "      <td>“Did he train you? Did he rehearse you? Did he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunset Boulevard (1950)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/great-movie-...</td>\n",
       "      <td>Billy Wilder's \"Sunset Boulevard” is the portr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>King Kong (1933)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/great-movie-...</td>\n",
       "      <td>On good days I consider \"Citizen Kane\" the sem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/great-movie-...</td>\n",
       "      <td>\"L.A. Confidential\" finished at No. 1 in a lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logan (2017)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/logan-2017</td>\n",
       "      <td>Is “Logan” more powerful because of what the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0            Vertigo (1958)   \n",
       "1   Sunset Boulevard (1950)   \n",
       "2          King Kong (1933)   \n",
       "3  L.A. Confidential (1997)   \n",
       "4              Logan (2017)   \n",
       "\n",
       "                                          review_url  \\\n",
       "0  http://www.rogerebert.com/reviews/great-movie-...   \n",
       "1  http://www.rogerebert.com/reviews/great-movie-...   \n",
       "2  http://www.rogerebert.com/reviews/great-movie-...   \n",
       "3  http://www.rogerebert.com/reviews/great-movie-...   \n",
       "4       http://www.rogerebert.com/reviews/logan-2017   \n",
       "\n",
       "                                         review_text  \n",
       "0  “Did he train you? Did he rehearse you? Did he...  \n",
       "1  Billy Wilder's \"Sunset Boulevard” is the portr...  \n",
       "2  On good days I consider \"Citizen Kane\" the sem...  \n",
       "3  \"L.A. Confidential\" finished at No. 1 in a lis...  \n",
       "4  Is “Logan” more powerful because of what the s...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Programming Interfaces\n",
    "- Getting each movies poster to add to our word cloud\n",
    "- We would scrap the image url from the html but a better way is to access  them through an API\n",
    "- APIs let us access data from the internet in a reasonably easy manner\n",
    "- There are many open source APIs, we'll use [mediaWiki](https://www.mediawiki.org/wiki/MediaWiki) which is an open source API for wikipedia\n",
    "\n",
    "### APIs and Access Libraries\n",
    "- THe goal is to get the movie poster images somehow\n",
    "- Rotten tomatoes does have an API and does provide audience scores which means we could have hit the API instead of scrapping it off of the Rotten Tomatoes web page. But the API doesn't provide posters and images in addition it requires you to apply for access before using it\n",
    "- When given a choice always use the API over scrapping. Scrapping is brittle and breaks with web layout redesigns because the underlying HTML has changed\n",
    "- APIs and their access libraries allow programmers to access data in a super simple manner\n",
    "- [rtsimple](https://pypi.org/project/rtsimple/) is an access library for rotten tomatoes that uses python. If we had permission to use the Rotten tomatoes API we could import rtsimple, use our API key, create an object for each movie and access the ratings data directly from the movie object\n",
    "\n",
    "    ```python\n",
    "    import rtsimple as rt\n",
    "    rt.api_key = '<your_api_key>'\n",
    "    movie = rt.Movies('<movie_id>')\n",
    "    movie.ratings['audience_score']\n",
    "    ```\n",
    "\n",
    "## MediaWiki API\n",
    "- API that holds all of the wikipedia data\n",
    "- THey have a great [tutorial](https://www.mediawiki.org/wiki/API:Tutorial) on their website on how their API calls are structured\n",
    "\n",
    "### wptools Library\n",
    "- There are a bunch of different access libraries for MediaWIki to satisfy the variety of programming languages that exist. Here's a [list](https://www.mediawiki.org/wiki/API:Client_code#Python) for python\n",
    "- This is pretty standard for most APIs , some libraries are better than others which again is standard.\n",
    "- For MediaWiki the most upto date and human readable one in python is called [wptools](https://github.com/siznax/wptools)\n",
    "- The analogous relationship for twitter is;\n",
    "    * MediaWiki API -> wptools\n",
    "    * Twitter API -> tweepy\n",
    "    \n",
    "- wptools has an even simpler tutorial on their github page using [Mahatma Gandthi Wikipedia Page](https://en.wikipedia.org/wiki/Mahatma_Gandhi) as a working example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get a `page` object the [usage](https://github.com/siznax/wptools/wiki/Usage#page-usage) is as follows;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahtma Gandhi is the last bit of the WikiPedia url for that page\n",
    "page = wptools.page('E.T._the_Extra-Terrestrial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "en.wikipedia.org (query) E.T._the_Extra-Terrestrial\n",
      "en.wikipedia.org (query) E.T. the Extra-Terrestrial (&plcontinue=...\n",
      "E.T. the Extra-Terrestrial (en) data\n",
      "{\n",
      "  WARNINGS: <dict(1)> extracts\n",
      "  aliases: <list(2)> E.T., ET\n",
      "  assessments: <dict(4)> United States, Film, Science Fiction, Lib...\n",
      "  description: 1982 film directed by Steven Spielberg\n",
      "  extext: <str(2186)> _**E.T. the Extra-Terrestrial**_ (or simply ...\n",
      "  extract: <str(2311)> <p class=\"mw-empty-elt\"></p><p><i><b>E.T. t...\n",
      "  label: E.T. the Extra-Terrestrial\n",
      "  length: 100,768\n",
      "  links: <list(630)> 12 Angry Men (1957 film), 12 Monkeys, 12 Year...\n",
      "  modified: <dict(1)> page\n",
      "  pageid: 73441\n",
      "  random: Brachyponera luteipes\n",
      "  redirects: <list(37)> {'pageid': 177061, 'ns': 0, 'title': 'E.T....\n",
      "  requests: <list(2)> query, query\n",
      "  title: E.T. the Extra-Terrestrial\n",
      "  url: https://en.wikipedia.org/wiki/E.T._the_Extra-Terrestrial\n",
      "  url_raw: <str(67)> https://en.wikipedia.org/wiki/E.T._the_Extra-...\n",
      "  watchers: 358\n",
      "  wikibase: Q11621\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q11621\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wptools.page.WPToolsPage at 0x7f58c16a41f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling get will automatically fetch extracts\n",
    "page.get_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E.T. the Extra-Terrestrial'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the image attribute will return the images for this page\n",
    "page.data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms\n",
    "- Access Library - A set of code that can be used to access an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON File Structure\n",
    "- Most data from APIs comes in JSON or XML format\n",
    "### JSON vs XML\n",
    "- JSON stands for JavaScript Object Notation\n",
    "- XML stands for eXtensible Markup Language\n",
    "\n",
    "- JSON is especially great for representing and accessing complicated data hierachies (sometimes we have data with fields that have multiple entries, sometimes fileds have sub fields)\n",
    "\n",
    "### JSON structure\n",
    "- JSON is built on two key structures;\n",
    "\n",
    "1. __JSON Objects__\n",
    "- JSON objects are a collection of key value pairs\n",
    "- In python JSON objects are intepretated as dictionaries and you can access them like you would a standard python dictionary\n",
    "- JSON object keys must be strings\n",
    "\n",
    "2. __JSON Arrays__\n",
    "- A JSON array is an ordered list of values sorrounded by square brackets\n",
    "- In Python JSON arrays are interpreted and accessed like lists\n",
    "\n",
    "- The values for both JSON objects and arrays can be any valid JSON data type: string, number, object, array, Boolean or null\n",
    "- When objects and arrays are combined it is called nesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Files in python\n",
    "### Accessing JSON files in python\n",
    "- JSON files can be accessed in python just like dictionaries and lists bacuse JSON objects are\n",
    "\n",
    "    ```python\n",
    "    infobox_json['Box office']\n",
    "    infobox_json['Produced by'][0]\n",
    "    infobox_json['Release'][1]['Location']\n",
    "    ```\n",
    "\n",
    "- With the knowledge on APIs, JSON and downloading files from the internet we now have the knowledge to download all of the movie poster images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's inspect the wptools page object for the [E.T. The Extra-Terrestial Wikipedia page](https://en.wikipedia.org/wiki/E.T._the_Extra-Terrestrial). In the Jupyter Notebook below, you will access the images and infobox attributes and the data within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "en.wikipedia.org (query) E.T._the_Extra-Terrestrial\n",
      "en.wikipedia.org (query) E.T. the Extra-Terrestrial (&plcontinue=...\n",
      "en.wikipedia.org (parse) 73441\n",
      "www.wikidata.org (wikidata) Q11621\n",
      "www.wikidata.org (labels) P214|P3129|P2603|P4786|P5693|Q652644|P1...\n",
      "www.wikidata.org (labels) Q1720784|P244|P2631|Q28732982|Q981030|Q...\n",
      "www.wikidata.org (labels) P2758|P646|P6398|P6839|Q7341915|Q103360...\n",
      "www.wikidata.org (labels) Q1748409|Q56887459|P5021|Q56887384|P725...\n",
      "www.wikidata.org (labels) Q237207|P3854|Q739633|P950|Q3897561|Q18...\n",
      "www.wikidata.org (labels) Q488651\n",
      "en.wikipedia.org (restbase) /page/summary/E.T._the_Extra-Terrestrial\n",
      "en.wikipedia.org (imageinfo) File:E t the extra terrestrial ver3....\n",
      "E.T. the Extra-Terrestrial (en) data\n",
      "{\n",
      "  WARNINGS: <dict(1)> extracts\n",
      "  aliases: <list(2)> E.T., ET\n",
      "  assessments: <dict(4)> United States, Film, Science Fiction, Lib...\n",
      "  claims: <dict(130)> P1562, P57, P272, P345, P31, P161, P373, P48...\n",
      "  description: 1982 American science fiction film\n",
      "  exhtml: <str(485)> <p><i><b>E.T. the Extra-Terrestrial</b></i> i...\n",
      "  exrest: <str(464)> E.T. the Extra-Terrestrial is a 1982 American...\n",
      "  extext: <str(2186)> _**E.T. the Extra-Terrestrial**_ (or simply ...\n",
      "  extract: <str(2311)> <p class=\"mw-empty-elt\"></p><p><i><b>E.T. t...\n",
      "  image: <list(4)> {'kind': 'parse-image', 'file': 'File:E t the e...\n",
      "  infobox: <dict(19)> name, image, alt, caption, director, produce...\n",
      "  iwlinks: <list(6)> https://commons.wikimedia.org/wiki/Category:E...\n",
      "  label: E.T. the Extra-Terrestrial\n",
      "  labels: <dict(251)> P214, P3129, P2603, P4786, P5693, Q652644, P...\n",
      "  length: 100,768\n",
      "  links: <list(630)> 12 Angry Men (1957 film), 12 Monkeys, 12 Year...\n",
      "  modified: <dict(2)> page, wikidata\n",
      "  pageid: 73441\n",
      "  parsetree: <str(123232)> <root><template><title>Redirect</title>...\n",
      "  random: Otonan\n",
      "  redirects: <list(37)> {'pageid': 177061, 'ns': 0, 'title': 'E.T....\n",
      "  requests: <list(12)> query, query, parse, wikidata, labels, labe...\n",
      "  title: E.T._the_Extra-Terrestrial\n",
      "  url: https://en.wikipedia.org/wiki/E.T._the_Extra-Terrestrial\n",
      "  url_raw: <str(67)> https://en.wikipedia.org/wiki/E.T._the_Extra-...\n",
      "  watchers: 358\n",
      "  what: film\n",
      "  wikibase: Q11621\n",
      "  wikidata: <dict(130)> AllMovie title ID (P1562), director (P57),...\n",
      "  wikidata_pageid: 13150\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q11621\n",
      "  wikitext: <str(100434)> {{Redirect|E.T.|other uses|ET (disambigu...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "page = wptools.page('E.T._the_Extra-Terrestrial').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'parse-image',\n",
       " 'file': 'File:E t the extra terrestrial ver3.jpg',\n",
       " 'orig': 'E t the extra terrestrial ver3.jpg',\n",
       " 'timestamp': '2016-06-04T10:30:46Z',\n",
       " 'size': 83073,\n",
       " 'width': 253,\n",
       " 'height': 394,\n",
       " 'url': 'https://upload.wikimedia.org/wikipedia/en/6/66/E_t_the_extra_terrestrial_ver3.jpg',\n",
       " 'descriptionurl': 'https://en.wikipedia.org/wiki/File:E_t_the_extra_terrestrial_ver3.jpg',\n",
       " 'descriptionshorturl': 'https://en.wikipedia.org/w/index.php?curid=7419503',\n",
       " 'title': 'File:E t the extra terrestrial ver3.jpg',\n",
       " 'metadata': {'DateTime': {'value': '2016-06-04 10:30:46',\n",
       "   'source': 'mediawiki-metadata',\n",
       "   'hidden': ''},\n",
       "  'ObjectName': {'value': 'E t the extra terrestrial ver3',\n",
       "   'source': 'mediawiki-metadata',\n",
       "   'hidden': ''},\n",
       "  'CommonsMetadataExtension': {'value': 1.2,\n",
       "   'source': 'extension',\n",
       "   'hidden': ''},\n",
       "  'Categories': {'value': 'All non-free media|E.T. the Extra-Terrestrial|Fair use images of film posters|Files with no machine-readable author|Noindexed pages|Wikipedia non-free files for NFUR review|Wikipedia non-free files with valid backlink',\n",
       "   'source': 'commons-categories',\n",
       "   'hidden': ''},\n",
       "  'Assessments': {'value': '', 'source': 'commons-categories', 'hidden': ''},\n",
       "  'ImageDescription': {'value': '<p>This is a poster for  <i>E.T. the Extra-Terrestrial</i>. <br>The poster art copyright is believed to belong to <a href=\"//en.wikipedia.org/wiki/John_Alvin\" title=\"John Alvin\">John Alvin</a>.\\n</p>',\n",
       "   'source': 'commons-desc-page'},\n",
       "  'Credit': {'value': '<p>The poster art can or could be obtained from <a href=\"//en.wikipedia.org/wiki/John_Alvin\" title=\"John Alvin\">John Alvin</a>.\\n</p>',\n",
       "   'source': 'commons-desc-page',\n",
       "   'hidden': ''},\n",
       "  'LicenseShortName': {'value': 'Fair use',\n",
       "   'source': 'commons-desc-page',\n",
       "   'hidden': ''},\n",
       "  'UsageTerms': {'value': '<a href=\"//en.wikipedia.org/wiki/Wikipedia:Non-free_use_rationale_guideline\" title=\"Wikipedia:Non-free use rationale guideline\">Fair use</a> of copyrighted material in the context of <a href=\"//en.wikipedia.org/wiki/E.T._the_Extra-Terrestrial\" title=\"E.T. the Extra-Terrestrial\">E.T. the Extra-Terrestrial</a>',\n",
       "   'source': 'commons-desc-page',\n",
       "   'hidden': ''},\n",
       "  'Attribution': {'value': '<p>The poster art can or could be obtained from <a href=\"//en.wikipedia.org/wiki/John_Alvin\" title=\"John Alvin\">John Alvin</a>.\\n</p>',\n",
       "   'source': 'commons-desc-page',\n",
       "   'hidden': ''},\n",
       "  'LicenseUrl': {'value': '//en.wikipedia.org/wiki/File:E_t_the_extra_terrestrial_ver3.jpg',\n",
       "   'source': 'commons-desc-page',\n",
       "   'hidden': ''},\n",
       "  'NonFree': {'value': 'true', 'source': 'commons-desc-page', 'hidden': ''},\n",
       "  'Copyrighted': {'value': 'True',\n",
       "   'source': 'commons-desc-page',\n",
       "   'hidden': ''},\n",
       "  'Restrictions': {'value': '', 'source': 'commons-desc-page', 'hidden': ''}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the first image in the images attribute, which is a JSON array.\n",
    "page.data['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[Steven Spielberg]]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the director key of the infobox attribute, which is a JSON object.\n",
    "page.data['infobox']['director']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More JSON in python\n",
    "- In the above example JSON data was sourced from an API. That isn't always the case though\n",
    "\n",
    "- Sometimes you are given a text file with human readable JSON within it. For this situation the [json](https://docs.python-guide.org/scenarios/json/) library is indispensable. It can parse JSON from strings or files and it can parse json into a python dictionary or list\n",
    "- It can also convert a python dictionaries or lists into JSON strings\n",
    "- [Reading and Writing JSON to a File in Python](https://stackabuse.com/reading-and-writing-json-to-a-file-in-python/)\n",
    "- Pandas also has JSON functions (`read_json` and `to_json` DataFrame method) but the hierachal advantage of json is wasted in pandas tabular dataframe so the uses are limited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mashup: APIs,Downloading files programmatically and JSON\n",
    "- Download all of the movie poster images for the Roger Ebert review word clouds\n",
    "\n",
    "- Two key things to be aware of;\n",
    "    1. Wikipedia Page Titles\n",
    "    - To access wikipedia page data via the MediaWiki API with wptools  you need each movie's wikipedia page title (what comes after the slash)\n",
    "\n",
    "    2.Downloading Image Files\n",
    "    - Downloading images may seem tricky from a reading and writing perspective in comparison to text files which you can read line by line\n",
    "    - But in reality image files arent special, they are just binary files\n",
    "    - To interract with them you don't need special software, you can use regular file opening, reading and writing techniques\n",
    "        \n",
    "        ```python\n",
    "        import requests\n",
    "        r = requests.get(url)\n",
    "        with open(folder_name + '/' + filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        ```\n",
    "    - This technique can be error prone. It will work most of the time but sometimes the file you write to will be damaged\n",
    "    - The erroes encountered is why request library maintainers recommend using the [PIL](https://pillow.readthedocs.io/en/stable/) library and `BytesIO` from the `io` library for non-text requests like images\n",
    "    - They recommend that you access the response body as bytes, for non-text requests. For example, to create an image from binary data returned by a request:\n",
    "        \n",
    "        ```python\n",
    "        import requests\n",
    "        from PIL import Image\n",
    "        from io import BytesIO\n",
    "        img = Image.open(BytesIO(r.content))\n",
    "        ```\n",
    "\n",
    "    - Though you may still encounter a similar file error this code above will atleast warn us with an error message at which point we can manually download the problematic images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "- Gather the last piece of data for the Roger Ebert review word clouds now: the movie poster image files\n",
    "- Let's also keep each image's URL to add to the master DataFrame later.\n",
    "- We'll use a loop and here's how the parts inside that loop will work in order;\n",
    "    * We're going to query the mediaWiki Api using `wptools` to get a movie poster URL via each page object's `image` attribute\n",
    "    * using that url we'll programmatically download that image into a folder called `bestofrt_posters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wptools\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = [\n",
    "    'The_Wizard_of_Oz_(1939_film)',\n",
    "    'Citizen_Kane',\n",
    "    'The_Third_Man',\n",
    "    'Get_Out_(film)',\n",
    "    'Mad_Max:_Fury_Road',\n",
    "    'The_Cabinet_of_Dr._Caligari',\n",
    "    'All_About_Eve',\n",
    "    'Inside_Out_(2015_film)',\n",
    "    'The_Godfather',\n",
    "    'Metropolis_(1927_film)',\n",
    "    'E.T._the_Extra-Terrestrial',\n",
    "    'Modern_Times_(film)',\n",
    "    'It_Happened_One_Night',\n",
    "    \"Singin'_in_the_Rain\",\n",
    "    'Boyhood_(film)',\n",
    "    'Casablanca_(film)',\n",
    "    'Moonlight_(2016_film)',\n",
    "    'Psycho_(1960_film)',\n",
    "    'Laura_(1944_film)',\n",
    "    'Nosferatu',\n",
    "    'Snow_White_and_the_Seven_Dwarfs_(1937_film)',\n",
    "    \"A_Hard_Day%27s_Night_(film)\",\n",
    "    'La_Grande_Illusion',\n",
    "    'North_by_Northwest',\n",
    "    'The_Battle_of_Algiers',\n",
    "    'Dunkirk_(2017_film)',\n",
    "    'The_Maltese_Falcon_(1941_film)',\n",
    "    'Repulsion_(film)',\n",
    "    '12_Years_a_Slave_(film)',\n",
    "    'Gravity_(2013_film)',\n",
    "    'Sunset_Boulevard_(film)',\n",
    "    'King_Kong_(1933_film)',\n",
    "    'Spotlight_(film)',\n",
    "    'The_Adventures_of_Robin_Hood',\n",
    "    'Rashomon',\n",
    "    'Rear_Window',\n",
    "    'Selma_(film)',\n",
    "    'Taxi_Driver',\n",
    "    'Toy_Story_3',\n",
    "    'Argo_(2012_film)',\n",
    "    'Toy_Story_2',\n",
    "    'The_Big_Sick',\n",
    "    'Bride_of_Frankenstein',\n",
    "    'Zootopia',\n",
    "    'M_(1931_film)',\n",
    "    'Wonder_Woman_(2017_film)',\n",
    "    'The_Philadelphia_Story_(film)',\n",
    "    'Alien_(film)',\n",
    "    'Bicycle_Thieves',\n",
    "    'Seven_Samurai',\n",
    "    'The_Treasure_of_the_Sierra_Madre_(film)',\n",
    "    'Up_(2009_film)',\n",
    "    '12_Angry_Men_(1957_film)',\n",
    "    'The_400_Blows',\n",
    "    'Logan_(film)',\n",
    "    'All_Quiet_on_the_Western_Front_(1930_film)',\n",
    "    'Army_of_Shadows',\n",
    "    'Arrival_(film)',\n",
    "    'Baby_Driver',\n",
    "    'A_Streetcar_Named_Desire_(1951_film)',\n",
    "    'The_Night_of_the_Hunter_(film)',\n",
    "    'Star_Wars:_The_Force_Awakens',\n",
    "    'Manchester_by_the_Sea_(film)',\n",
    "    'Dr._Strangelove',\n",
    "    'Frankenstein_(1931_film)',\n",
    "    'Vertigo_(film)',\n",
    "    'The_Dark_Knight_(film)',\n",
    "    'Touch_of_Evil',\n",
    "    'The_Babadook',\n",
    "    'The_Conformist_(film)',\n",
    "    'Rebecca_(1940_film)',\n",
    "    \"Rosemary%27s_Baby_(film)\",\n",
    "    'Finding_Nemo',\n",
    "    'Brooklyn_(film)',\n",
    "    'The_Wrestler_(2008_film)',\n",
    "    'The_39_Steps_(1935_film)',\n",
    "    'L.A._Confidential_(film)',\n",
    "    'Gone_with_the_Wind_(film)',\n",
    "    'The_Good,_the_Bad_and_the_Ugly',\n",
    "    'Skyfall',\n",
    "    'Rome,_Open_City',\n",
    "    'Tokyo_Story',\n",
    "    'Hell_or_High_Water_(film)',\n",
    "    'Pinocchio_(1940_film)',\n",
    "    'The_Jungle_Book_(2016_film)',\n",
    "    'La_La_Land_(film)',\n",
    "    'Star_Trek_(film)',\n",
    "    'High_Noon',\n",
    "    'Apocalypse_Now',\n",
    "    'On_the_Waterfront',\n",
    "    'The_Wages_of_Fear',\n",
    "    'The_Last_Picture_Show',\n",
    "    'Harry_Potter_and_the_Deathly_Hallows_–_Part_2',\n",
    "    'The_Grapes_of_Wrath_(film)',\n",
    "    'Roman_Holiday',\n",
    "    'Man_on_Wire',\n",
    "    'Jaws_(film)',\n",
    "    'Toy_Story',\n",
    "    'The_Godfather_Part_II',\n",
    "    'Battleship_Potemkin'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'bestofrt_posters'\n",
    "# Make directory if it doesn't already exist\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1_The_Wizard_of_Oz_(1939_film): cannot identify image file <_io.BytesIO object at 0x7f98a07f6ef0>\n",
      "2\n",
      "2_Citizen_Kane: cannot identify image file <_io.BytesIO object at 0x7f98ccf454f0>\n",
      "3\n",
      "3_The_Third_Man: cannot identify image file <_io.BytesIO object at 0x7f98a0b1bf40>\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "7_All_About_Eve: cannot identify image file <_io.BytesIO object at 0x7f98a0a0e590>\n",
      "8\n",
      "9\n",
      "10\n",
      "10_Metropolis_(1927_film): cannot identify image file <_io.BytesIO object at 0x7f98a0867450>\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "14_Singin'_in_the_Rain: cannot identify image file <_io.BytesIO object at 0x7f98a07f6180>\n",
      "15\n",
      "15_Boyhood_(film): 'image'\n",
      "16\n",
      "17\n",
      "18\n",
      "18_Psycho_(1960_film): cannot identify image file <_io.BytesIO object at 0x7f98a0886680>\n",
      "19\n",
      "19_Laura_(1944_film): cannot identify image file <_io.BytesIO object at 0x7f98a14066d0>\n",
      "20\n",
      "20_Nosferatu: cannot identify image file <_io.BytesIO object at 0x7f98a143ad60>\n",
      "21\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "API error: {'code': 'invalidtitle', 'info': 'Bad title \"A_Hard_Day%27s_Night_(film)\".', 'docref': 'See https://en.wikipedia.org/w/api.php for API usage. Subscribe to the mediawiki-api-announce mailing list at &lt;https://lists.wikimedia.org/postorius/lists/mediawiki-api-announce.lists.wikimedia.org/&gt; for notice of API deprecations and breaking changes.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22_A_Hard_Day%27s_Night_(film): https://en.wikipedia.org/w/api.php?action=parse&formatversion=2&contentmodel=text&disableeditsection=&disablelimitreport=&disabletoc=&prop=text|iwlinks|parsetree|wikitext|displaytitle|properties&redirects&page=A_Hard_Day%2527s_Night_%28film%29\n",
      "23\n",
      "24\n",
      "24_North_by_Northwest: cannot identify image file <_io.BytesIO object at 0x7f98a0890360>\n",
      "25\n",
      "26\n",
      "27\n",
      "27_The_Maltese_Falcon_(1941_film): cannot identify image file <_io.BytesIO object at 0x7f989b9eba40>\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "32_King_Kong_(1933_film): cannot identify image file <_io.BytesIO object at 0x7f98a08a19a0>\n",
      "33\n",
      "33_Spotlight_(film): https://en.wikipedia.org/w/api.php?action=query&exintro&formatversion=2&inprop=url|watchers&list=random&pithumbsize=240&pllimit=500&ppprop=disambiguation|wikibase_item&prop=extracts|info|links|pageassessments|pageimages|pageprops|pageterms|redirects&redirects&rdlimit=500&rnlimit=1&rnnamespace=0&titles=Spotlight%20%28film%29&plcontinue=43842546|0|Satellite_Award_for_Best_Supporting_Actress_–_Motion_Picture\n",
      "34\n",
      "34_The_Adventures_of_Robin_Hood: cannot identify image file <_io.BytesIO object at 0x7f98a0a0e630>\n",
      "35\n",
      "35_Rashomon: cannot identify image file <_io.BytesIO object at 0x7f98a085c8b0>\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "40_Argo_(2012_film): https://en.wikipedia.org/w/api.php?action=query&exintro&formatversion=2&inprop=url|watchers&list=random&pithumbsize=240&pllimit=500&ppprop=disambiguation|wikibase_item&prop=extracts|info|links|pageassessments|pageimages|pageprops|pageterms|redirects&redirects&rdlimit=500&rnlimit=1&rnnamespace=0&titles=Argo%20%282012%20film%29&plcontinue=33028800|0|Uganda–Tanzania_War\n",
      "41\n",
      "42\n",
      "43\n",
      "43_Bride_of_Frankenstein: cannot identify image file <_io.BytesIO object at 0x7f98a0a09770>\n",
      "44\n",
      "44_Zootopia: cannot identify image file <_io.BytesIO object at 0x7f98a140d180>\n",
      "45\n",
      "46\n",
      "47\n",
      "47_The_Philadelphia_Story_(film): cannot identify image file <_io.BytesIO object at 0x7f989b9d1540>\n",
      "48\n",
      "49\n",
      "50\n",
      "50_Seven_Samurai: cannot identify image file <_io.BytesIO object at 0x7f989b9c9d60>\n",
      "51\n",
      "51_The_Treasure_of_the_Sierra_Madre_(film): cannot identify image file <_io.BytesIO object at 0x7f98a0b8ef90>\n",
      "52\n",
      "53\n",
      "54\n",
      "54_The_400_Blows: cannot identify image file <_io.BytesIO object at 0x7f98a0880d60>\n",
      "55\n",
      "56\n",
      "56_All_Quiet_on_the_Western_Front_(1930_film): cannot identify image file <_io.BytesIO object at 0x7f98ccf454f0>\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "60_A_Streetcar_Named_Desire_(1951_film): cannot identify image file <_io.BytesIO object at 0x7f98a0a097c0>\n",
      "61\n",
      "61_The_Night_of_the_Hunter_(film): cannot identify image file <_io.BytesIO object at 0x7f98a142de00>\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "66_Vertigo_(film): cannot identify image file <_io.BytesIO object at 0x7f98a0b1b9f0>\n",
      "67\n",
      "68\n",
      "68_Touch_of_Evil: cannot identify image file <_io.BytesIO object at 0x7f989b772db0>\n",
      "69\n",
      "70\n",
      "71\n",
      "71_Rebecca_(1940_film): cannot identify image file <_io.BytesIO object at 0x7f98a085c770>\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "API error: {'code': 'invalidtitle', 'info': 'Bad title \"Rosemary%27s_Baby_(film)\".', 'docref': 'See https://en.wikipedia.org/w/api.php for API usage. Subscribe to the mediawiki-api-announce mailing list at &lt;https://lists.wikimedia.org/postorius/lists/mediawiki-api-announce.lists.wikimedia.org/&gt; for notice of API deprecations and breaking changes.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72_Rosemary%27s_Baby_(film): https://en.wikipedia.org/w/api.php?action=parse&formatversion=2&contentmodel=text&disableeditsection=&disablelimitreport=&disabletoc=&prop=text|iwlinks|parsetree|wikitext|displaytitle|properties&redirects&page=Rosemary%2527s_Baby_%28film%29\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "78_Gone_with_the_Wind_(film): cannot identify image file <_io.BytesIO object at 0x7f98a088cb80>\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "82_Tokyo_Story: cannot identify image file <_io.BytesIO object at 0x7f98a140d040>\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "90_On_the_Waterfront: cannot identify image file <_io.BytesIO object at 0x7f98a0b8e220>\n",
      "91\n",
      "91_The_Wages_of_Fear: cannot identify image file <_io.BytesIO object at 0x7f989b7669f0>\n",
      "92\n",
      "93\n",
      "94\n",
      "94_The_Grapes_of_Wrath_(film): cannot identify image file <_io.BytesIO object at 0x7f98a0a38c20>\n",
      "95\n",
      "95_Roman_Holiday: cannot identify image file <_io.BytesIO object at 0x7f989b9114f0>\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "100_Battleship_Potemkin: cannot identify image file <_io.BytesIO object at 0x7f98a08a1f40>\n"
     ]
    }
   ],
   "source": [
    "# List of dictionaries to build and convert to a DataFrame later\n",
    "df_list = []\n",
    "image_errors = {}\n",
    "for title in title_list:\n",
    "    try:\n",
    "        # This cell is slow so print ranking to gauge time remaining\n",
    "        ranking = title_list.index(title) + 1\n",
    "        print(ranking)\n",
    "        page = wptools.page(title, silent=True)\n",
    "        # Your code here (three lines)\n",
    "        images = page.get().data['image']\n",
    "        # First image is usually the poster\n",
    "        first_image_url = images[0]['url']\n",
    "        r = requests.get(first_image_url)\n",
    "        # Download movie poster image\n",
    "        i = Image.open(BytesIO(r.content))\n",
    "        image_file_format = first_image_url.split('.')[-1]\n",
    "        i.save(folder_name + \"/\" + str(ranking) + \"_\" + title + '.' + image_file_format)\n",
    "        # Append to list of dictionaries\n",
    "        df_list.append({'ranking': int(ranking),\n",
    "                        'title': title,\n",
    "                        'poster_url': first_image_url})\n",
    "\n",
    "    # Not best practice to catch all exceptions but fine for this short script\n",
    "    except Exception as e:\n",
    "        print(str(ranking) + \"_\" + title + \": \" + str(e))\n",
    "        image_errors[str(ranking) + \"_\" + title] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_Citizen_Kane\n",
      "3_The_Third_Man\n",
      "6_The_Cabinet_of_Dr._Caligari\n",
      "7_All_About_Eve\n",
      "10_Metropolis_(1927_film)\n",
      "13_It_Happened_One_Night\n",
      "14_Singin'_in_the_Rain\n",
      "15_Boyhood_(film)\n",
      "18_Psycho_(1960_film)\n",
      "19_Laura_(1944_film)\n",
      "20_Nosferatu\n",
      "22_A_Hard_Day%27s_Night_(film)\n",
      "24_North_by_Northwest\n",
      "27_The_Maltese_Falcon_(1941_film)\n",
      "28_Repulsion_(film)\n",
      "31_Sunset_Boulevard_(film)\n",
      "32_King_Kong_(1933_film)\n",
      "33_Spotlight_(film)\n",
      "34_The_Adventures_of_Robin_Hood\n",
      "35_Rashomon\n",
      "40_Argo_(2012_film)\n",
      "43_Bride_of_Frankenstein\n",
      "45_M_(1931_film)\n",
      "47_The_Philadelphia_Story_(film)\n",
      "50_Seven_Samurai\n",
      "51_The_Treasure_of_the_Sierra_Madre_(film)\n",
      "53_12_Angry_Men_(1957_film)\n",
      "54_The_400_Blows\n",
      "56_All_Quiet_on_the_Western_Front_(1930_film)\n",
      "57_Army_of_Shadows\n",
      "60_A_Streetcar_Named_Desire_(1951_film)\n",
      "61_The_Night_of_the_Hunter_(film)\n",
      "65_Frankenstein_(1931_film)\n",
      "66_Vertigo_(film)\n",
      "68_Touch_of_Evil\n",
      "69_The_Babadook\n",
      "71_Rebecca_(1940_film)\n",
      "72_Rosemary%27s_Baby_(film)\n",
      "76_The_39_Steps_(1935_film)\n",
      "82_Tokyo_Story\n",
      "88_High_Noon\n",
      "90_On_the_Waterfront\n",
      "92_The_Last_Picture_Show\n",
      "93_Harry_Potter_and_the_Deathly_Hallows_–_Part_2\n",
      "94_The_Grapes_of_Wrath_(film)\n",
      "95_Roman_Holiday\n",
      "96_Man_on_Wire\n",
      "100_Battleship_Potemkin\n"
     ]
    }
   ],
   "source": [
    "for key in image_errors.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'he_Wizard_of_Oz_(1939_film)' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-21400a637b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://upload.wikimedia.org/wikipedia/en/d/df/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank_title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     df_list.append({'ranking': int(title_list.index(title) + 1),\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     'poster_url': url})\n",
      "\u001b[0;31mValueError\u001b[0m: 'he_Wizard_of_Oz_(1939_film)' is not in list"
     ]
    }
   ],
   "source": [
    "# Inspect unidentifiable images and download them individually\n",
    "for rank_title, images in image_errors.items():\n",
    "    if rank_title == '22_A_Hard_Day%27s_Night_(film)':\n",
    "        url = 'https://upload.wikimedia.org/wikipedia/en/4/47/A_Hard_Days_night_movieposter.jpg'\n",
    "    if rank_title == '53_12_Angry_Men_(1957_film)':\n",
    "        url = 'https://upload.wikimedia.org/wikipedia/en/9/91/12_angry_men.jpg'\n",
    "    if rank_title == '72_Rosemary%27s_Baby_(film)':\n",
    "        url = 'https://upload.wikimedia.org/wikipedia/en/e/ef/Rosemarys_baby_poster.jpg'\n",
    "    if rank_title == '93_Harry_Potter_and_the_Deathly_Hallows_–_Part_2':\n",
    "        url = 'https://upload.wikimedia.org/wikipedia/en/d/df/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2.jpg'\n",
    "    title = rank_title[3:]\n",
    "    df_list.append({'ranking': int(title_list.index(title) + 1),\n",
    "                    'title': title,\n",
    "                    'poster_url': url})\n",
    "    r = requests.get(url)\n",
    "    # Download movie poster image\n",
    "    i = Image.open(BytesIO(r.content))\n",
    "    image_file_format = url.split('.')[-1]\n",
    "    i.save(folder_name + \"/\" + rank_title + '.' + image_file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>title</th>\n",
       "      <th>poster_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Get_Out_(film)</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/a/a3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Mad_Max:_Fury_Road</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/6/6e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>The_Cabinet_of_Dr._Caligari</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/2/2f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Inside_Out_(2015_film)</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/0/0a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The_Godfather</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/1/1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>93</td>\n",
       "      <td>Harry_Potter_and_the_Deathly_Hallows_–_Part_2</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/d/df...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>96</td>\n",
       "      <td>Man_on_Wire</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/5/54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>97</td>\n",
       "      <td>Jaws_(film)</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/e/eb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>98</td>\n",
       "      <td>Toy_Story</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/1/13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>99</td>\n",
       "      <td>The_Godfather_Part_II</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/0/03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ranking                                          title  \\\n",
       "0         4                                 Get_Out_(film)   \n",
       "1         5                             Mad_Max:_Fury_Road   \n",
       "2         6                    The_Cabinet_of_Dr._Caligari   \n",
       "3         8                         Inside_Out_(2015_film)   \n",
       "4         9                                  The_Godfather   \n",
       "..      ...                                            ...   \n",
       "57       93  Harry_Potter_and_the_Deathly_Hallows_–_Part_2   \n",
       "58       96                                    Man_on_Wire   \n",
       "59       97                                    Jaws_(film)   \n",
       "60       98                                      Toy_Story   \n",
       "61       99                          The_Godfather_Part_II   \n",
       "\n",
       "                                           poster_url  \n",
       "0   https://upload.wikimedia.org/wikipedia/en/a/a3...  \n",
       "1   https://upload.wikimedia.org/wikipedia/en/6/6e...  \n",
       "2   https://upload.wikimedia.org/wikipedia/en/2/2f...  \n",
       "3   https://upload.wikimedia.org/wikipedia/en/0/0a...  \n",
       "4   https://upload.wikimedia.org/wikipedia/en/1/1c...  \n",
       "..                                                ...  \n",
       "57  https://upload.wikimedia.org/wikipedia/en/d/df...  \n",
       "58  https://upload.wikimedia.org/wikipedia/en/5/54...  \n",
       "59  https://upload.wikimedia.org/wikipedia/en/e/eb...  \n",
       "60  https://upload.wikimedia.org/wikipedia/en/1/13...  \n",
       "61  https://upload.wikimedia.org/wikipedia/en/0/03...  \n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame from list of dictionaries\n",
    "df = pd.DataFrame(df_list, columns=['ranking', 'title', 'poster_url'])\n",
    "df = df.sort_values('ranking').reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roger Ebert Word Clouds\n",
    "- We've now gathered the data to produce our second goal visualization, the Roger Ebert Review Wordcloud\n",
    "\n",
    "- Next we have to access and clean the data but in this notebook we focus solely on gathering\n",
    "- The word clouds have been pre-gathered in the word clouds folder\n",
    "- These word clouds required gathering data from two different sources: downloading files from the internet, i.e the Roger Ebert review text files and accessing data from an API i.e the movie poster urls. And this data was in two formats `.txt` and `JSON`\n",
    "- Data visualization can be informative but it can also be art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroing Data\n",
    "- Storing data is usually done after cleaning but it is not usually done which excludes it from being part of the data wrangling process\n",
    "- Sometimes you just analyze and visualize and leave it at that without saving your new data\n",
    "\n",
    "- Imagine you've assessed and cleaned your data which includes merging all these separate pieces of data. What do you want to do next?\n",
    "- There are two popular options, saving to a database and saving to a file. For tabular data like we have here both files like csv files in databases are used a ton. The right solution depends on your dataset and the infrastructure you use in your daily work\n",
    "- Saving to a csv file is easy and is probably the best solution for a simple dataset like this one\n",
    "- The `to_csv` dataframe method is all you need and the only parameter required to save a file on your computer is the filepath to which you want to save this file. Often specifying `index=False` is necessary too if you don't want the dataframe index showing up as a column in your stored dataset\n",
    "    ```python\n",
    "    df.to_csv('dataset.csv', index=False)\n",
    "    ```\n",
    "- Saving data in a database is advantageous though, they are fast, they scale well as your data grows in size and you can ask them questions using languages like SQL. THey are very powerful and database skills are hugely in demand in todays workplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational Database Structure\n",
    "- A database is an organized collection of data that is structured to facilitate the storage, retrieval, modification and deletion of data\n",
    "- There are two main types of databases; relational databases and non relational databases with relational being the most popular\n",
    "- Structured Query Language, SQL is the standard language for communicating with relational databases\n",
    "\n",
    "### Why do Data Analysts use Relational Databases ans SQL?\n",
    "- Alot of the world's data live in databases and most of the world's databases are accessed using SQL\n",
    "- SQL is the most common method for accessing data and databases today. It has a variety of functions that allows its users to read, manipulate and change data\n",
    "\n",
    "- It's popular for data analysis because;\n",
    "    * It's easy to understand and learn\n",
    "    * It can access data directly from where its stored\n",
    "    * Its easy to audit and replicate\n",
    "    - It can run queries on multiple tables at once, across large datasets\n",
    "    * It can answer complex questions with more detail and depth compared to other analytic tools\n",
    "\n",
    "### Why do Businesses choose relational databases and SQL\n",
    "- Nearly all applications have a need to store data so that it can be accesed later and SQL is the language that allows analysts and others to access that information\n",
    "- Databases have a number of attributes that make them great for this:\n",
    "    * They check for data integrity to make sure that data is entered in the appropriate foramt\n",
    "    * They are fast across large datasets and can be optimized for greater speed\n",
    "    * They are shared entities meaning many people can access the same data at the same time\n",
    "    * They have administrative features like access controls\n",
    "\n",
    "- [Cornell: Relational Databases - Not your Father's Flat Files](https://www.cac.cornell.edu/education/Training/DataAnalysis/RelationalDatabases.pdf)\n",
    "\n",
    "### How Relational Databases Store Data\n",
    "- If you've used excel you should already be familiar with tables, they are similar to spread sheets.Tables have rows and columns just like Excel but have some more rigid rules\n",
    "\n",
    "- Database tables for instance are organized by column:\n",
    "    * Each column must have a unique name\n",
    "    * In a spreadsheet each cell can have its own data type but in database tables all the data in a column must be of the same type\n",
    "    * Descriptive column names are important\n",
    "- While the data type must be consistent the database doesn't necessarily know that a number means latitiude or the text is a name of a company that's why descriptive number\n",
    "\n",
    "### Types of SQL statements\n",
    "- SQL has a few basic elements. The most basic of which is a statement;\n",
    "    * statement - think of it as a piece of correctly written SQL code to tell the database what you want to do\n",
    "    * `CREATE` - creates a new table in the database\n",
    "    * `DROP TABLE` - removes a table from the database\n",
    "    * `SELECT` - allows you to read and display data, aka queries\n",
    "\n",
    "    ##### `SELECT` and `FROM`\n",
    "    - Important questions of every query start with two mandatory clauses or command words;\n",
    "        * `FROM` - What data do you want to pull from? What table of data do you want to use\n",
    "        * `SELECT` - Which elements from the database do you want to pull? What columns do you want to pull from the table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational databases in Python\n",
    "### Data Wrangling and Relational Databases\n",
    "- In the context of data wrangling, databases and SQL shold only come into play for gathering and/or storing data. That is\n",
    "    * __1. Connecting to a database and importing data__ into a pandas DataFrame then assessing and cleaning that data\n",
    "    * __2. Connecting to a database and storing data__ you just gathered (which could be potentially from a database), assessed and cleaned\n",
    "\n",
    "- These tasks are especially necessary when you have large amounts of data which is where SQL and other databases excel over flat files\n",
    "- The two scenarios above can be further broken down into three main tasks:\n",
    "    * __1. Connecting to a database in python__\n",
    "    * __2. Storing data from a pandas dataFrame in a database to which you are connected__\n",
    "    * __3. Importing data from a database to which you are connected to a pandas DataFrame__\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the steps below we are going to;\n",
    "\n",
    "     * Connect to a database. We'll connect to a SQLite database using [SQLAlchemy](https://www.sqlalchemy.org/) a database toolkit for python\n",
    "     * Store the data in the cleaned master dataset in the database. We'll do this using pandas `to_sql` DataFrame method\n",
    "     * Then read the brand  new data in that database back into a pandas DataFrame. We'll do this using pandas `read_sql` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational databases and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '/home/mark/data_science/Udacity/data_analysis/2-introduction_to_data-analysis/case_studies/second/fuel-economy-datasets/all_alpha_08_clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>displ</th>\n",
       "      <th>cyl</th>\n",
       "      <th>trans</th>\n",
       "      <th>drive</th>\n",
       "      <th>fuel</th>\n",
       "      <th>cert_region</th>\n",
       "      <th>veh_class</th>\n",
       "      <th>air_pollution_score</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>hwy_mpg</th>\n",
       "      <th>cmb_mpg</th>\n",
       "      <th>greenhouse_gas_score</th>\n",
       "      <th>smartway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACURA MDX</td>\n",
       "      <td>3.7</td>\n",
       "      <td>(6 cyl)</td>\n",
       "      <td>Auto-S5</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>CA</td>\n",
       "      <td>SUV</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACURA MDX</td>\n",
       "      <td>3.7</td>\n",
       "      <td>(6 cyl)</td>\n",
       "      <td>Auto-S5</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>FA</td>\n",
       "      <td>SUV</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACURA RDX</td>\n",
       "      <td>2.3</td>\n",
       "      <td>(4 cyl)</td>\n",
       "      <td>Auto-S5</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>CA</td>\n",
       "      <td>SUV</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  displ      cyl    trans drive      fuel cert_region veh_class  \\\n",
       "0  ACURA MDX    3.7  (6 cyl)  Auto-S5   4WD  Gasoline          CA       SUV   \n",
       "1  ACURA MDX    3.7  (6 cyl)  Auto-S5   4WD  Gasoline          FA       SUV   \n",
       "2  ACURA RDX    2.3  (4 cyl)  Auto-S5   4WD  Gasoline          CA       SUV   \n",
       "\n",
       "  air_pollution_score city_mpg hwy_mpg cmb_mpg greenhouse_gas_score smartway  \n",
       "0                   7       15      20      17                    4       no  \n",
       "1                   6       15      20      17                    4       no  \n",
       "2                   7       17      22      19                    5       no  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQLAlchemy Engine and empty bestofrt database\n",
    "# bestofrt.db will not show up in the Jupyter No\n",
    "engine = create_engine('sqlite:///all_alpha_08_clean.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store pandas DataFrame in a database\n",
    "- Store the data in the cleaned master dataset (bestofrt_master) in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store cleaned master DataFrame ('df') in a table called master in bestofrt.db\n",
    "# bestofrt.db will be visible now in the Jupyter Notebook dashboard\n",
    "df.to_sql('master', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read database data into a pandas DataFrame\n",
    "- Read the brand new data in that database back into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gather = pd.read_sql('SELECT * FROM master', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>displ</th>\n",
       "      <th>cyl</th>\n",
       "      <th>trans</th>\n",
       "      <th>drive</th>\n",
       "      <th>fuel</th>\n",
       "      <th>cert_region</th>\n",
       "      <th>veh_class</th>\n",
       "      <th>air_pollution_score</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>hwy_mpg</th>\n",
       "      <th>cmb_mpg</th>\n",
       "      <th>greenhouse_gas_score</th>\n",
       "      <th>smartway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACURA MDX</td>\n",
       "      <td>3.7</td>\n",
       "      <td>(6 cyl)</td>\n",
       "      <td>Auto-S5</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>CA</td>\n",
       "      <td>SUV</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACURA MDX</td>\n",
       "      <td>3.7</td>\n",
       "      <td>(6 cyl)</td>\n",
       "      <td>Auto-S5</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>FA</td>\n",
       "      <td>SUV</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACURA RDX</td>\n",
       "      <td>2.3</td>\n",
       "      <td>(4 cyl)</td>\n",
       "      <td>Auto-S5</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>CA</td>\n",
       "      <td>SUV</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  displ      cyl    trans drive      fuel cert_region veh_class  \\\n",
       "0  ACURA MDX    3.7  (6 cyl)  Auto-S5   4WD  Gasoline          CA       SUV   \n",
       "1  ACURA MDX    3.7  (6 cyl)  Auto-S5   4WD  Gasoline          FA       SUV   \n",
       "2  ACURA RDX    2.3  (4 cyl)  Auto-S5   4WD  Gasoline          CA       SUV   \n",
       "\n",
       "  air_pollution_score city_mpg hwy_mpg cmb_mpg greenhouse_gas_score smartway  \n",
       "0                   7       15      20      17                    4       no  \n",
       "1                   6       15      20      17                    4       no  \n",
       "2                   7       17      22      19                    5       no  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gather.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling in SQL?\n",
    "- Data wrangling can actually be performed in SQL\n",
    "- Pandas is better eqipped for gathering (pandas has a huge simplicity advantage in this area), assessing and cleaning data so its recommended to use pandas\n",
    "\n",
    "- [Reddit thread that debates pandas vs SQL](https://www.reddit.com/r/Python/comments/1tqjt4/why_do_you_use_pandas_instead_of_sql/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03f636c35d13881eb7879c84cc6ec4200ae0477cb88e4567894b219402d34418"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('mysite')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
